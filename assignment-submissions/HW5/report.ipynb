{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# RAID-5 #\n",
    "\n",
    "- [RAID-5](#raid-5)\n",
    "  - [Introduction](#introduction)\n",
    "  - [Design and Implementation ](#design-and-implementation-)\n",
    "    - [Client/Server Architecture](#clientserver-architecture)\n",
    "    - [Load Distribution](#load-distribution)\n",
    "    - [Fault Tolerance](#fault-tolerance)\n",
    "      - [Parity](#parity)\n",
    "      - [Checksum](#checksum)\n",
    "    - [Recovery](#recovery)\n",
    "      - [Block Recovery](#block-recovery)\n",
    "      - [Server Recovery](#server-recovery)\n",
    "      - [Failover](#failover)\n",
    "  - [Evaluation ](#evaluation-)\n",
    "  - [Reproducibility ](#reproducibility-)\n",
    "    - [Failover and Server Failure](#failover-and-server-failure)\n",
    "    - [Corrupt block](#corrupt-block)\n",
    "  - [Conclusions ](#conclusions-)\n",
    "\n",
    "## Introduction<a name=\"introduction\"></a> ##\n",
    "\n",
    "Describe in your own words what your project accomplishes, and motivate the decisions made\n",
    "\n",
    "## Design and Implementation <a name=\"design\"></a> ##\n",
    "\n",
    "### Client/Server Architecture ###\n",
    "\n",
    "### Load Distribution ###\n",
    "\n",
    "There are a couple reasons to distribute the data across multiple servers -\n",
    "\n",
    "1. Reduced server load by distributing requests\n",
    "2. Increased fault tolerance\n",
    "\n",
    "To achive data distribution the project employs RAID-5 methodology. RAID 5 distributes the parity along with the data across the servers available.\n",
    "\n",
    "The client will be aware of the data blocks. The number of servers and the distribution of requests will be handled by the RAID 5 by mapping the client block number to a server number and physical block number.\n",
    "\n",
    "The distribution pattern is shown in the Figure 1.\n",
    "\n",
    "![Figure 1. Data and Parity Distribution](image-3.png)\n",
    "\n",
    "Virtual to physical mapping mechanism is handled by two methods `MapVirtualBlockToPhysicalAddress` and `MapPhysicalAddressToVirtualBlock`. For example, given the virtual block number `10` the program will be able to map it with server `2` and block index `3` and vice-verca.\n",
    "\n",
    "Both of the functions are designed to skip the parity blocks and make sure client only have access to data blocks.\n",
    "\n",
    "![Figure 2. Data Strip - Participating Blocks in Recovery](image-5.png)\n",
    "\n",
    "Data strip is defined as the set of blocks for a given block index across all of the servers, as shown in Figure 2. Each data strip contains a parity associated and stored on one of the servers.\n",
    "\n",
    "The parity location is determined by the method `GetParityServer` given the block index. For example, for block index `3`, the program is able to determine the parity server i.e. `0`.\n",
    "\n",
    "Mapping method also includes a helper `GetBlockNumberOnStrip` which provides all of the blocks available across a data strip. This is useful while determining the parity, block and server recovery procedures.\n",
    "\n",
    "### Fault Tolerance ###\n",
    "\n",
    "Project is designed to tolerate two types of failures. Both of the failures employ data recovery utilizing the other data blocks and the parity block on the given data strip.\n",
    "\n",
    "1. Server Failure:\n",
    "  \n",
    "   The goal is to be able to continue to operate even after a complete server crashes. And when it recovers from the crash, a client should be able to recover the data using other blocks and parity on that data strip.\n",
    "\n",
    "2. Corrupt Block:\n",
    "\n",
    "    Here, a particular block data could get corrupt and we implement checksum to validate the data to ensure that the data is correct before sending it back to the client.\n",
    "\n",
    "    If the data is corrupt we recover the data using the recovery method which includes the parity and other data blocks on the data strip.\n",
    "  \n",
    "#### Parity ####\n",
    "\n",
    "Parity calculation is handled through `GetParity` method. There are two scenarios which are handled -\n",
    "\n",
    "a. when the parity is being created for the first ever time for the data strip. In this case we fetch all of the data block on the strip and then calculate the parity.\n",
    "\n",
    "```python\n",
    "# GetParity()\n",
    "# ...\n",
    "# ...\n",
    "  # create parity with data on the strip - data blocks\n",
    "  strip = self.GetBlockNumberAcrossServers(block_idx)\n",
    "  blocks = strip[0]\n",
    "  data = self.FetchDataBlocks(blocks)\n",
    "  # calculate and return parity \n",
    "  new_parity = self.CalculateParity(data)\n",
    "# ...\n",
    "# ...\n",
    "```\n",
    "\n",
    "b. When some parity already exist on the strip and certain block data is updated on the strip. Here, we could leverage the previously calculated parity and the new data to determine new parity -\n",
    "\n",
    "```python\n",
    "# GetParity()\n",
    "# ...\n",
    "# ...\n",
    "  data = [old_data, new_data, old_parity]\n",
    "  # calculate and return parity \n",
    "  new_parity = self.CalculateParity(data)\n",
    "# ...\n",
    "# ...\n",
    "```\n",
    "\n",
    "Parity is calculated using a bitwise xor operation handled in `CalculateParity` method.\n",
    "\n",
    "#### Checksum ####\n",
    "\n",
    "While writing to a block on the server, we keep a checksum, calculated using `hashlib.md5` method. and store in a dictionary.\n",
    "\n",
    "```python\n",
    "# PUT()\n",
    "# ...\n",
    "# ...\n",
    "    block_checksum = hashlib.md5(data.data).hexdigest()\n",
    "    # emulating corruption\n",
    "    print('>>> Checksum Returned From PUT Server ', cblk, block_number)\n",
    "    if block_number == cblk and RawBlocks.make_corrupt: \n",
    "       RawBlocks.make_corrupt = False\n",
    "       block_checksum = block_checksum[:5] + '12345'\n",
    "    RawBlocks.checksum[block_number] = block_checksum\n",
    "# ...\n",
    "# ...\n",
    "```\n",
    "\n",
    "This is then verified while reading the data and recalculating the checksum of the data and comparing it with the saved checksum. If any discrepancy is found, we report the error as `CHECKSUM_ERROR` on the client.\n",
    "\n",
    "```python\n",
    "# GET()\n",
    "# ...\n",
    "# ...\n",
    "    has_error = False\n",
    "    result = RawBlocks.block[block_number]\n",
    "    current_checksum = hashlib.md5(result).hexdigest()\n",
    "    # fetch checksum from cache\n",
    "    block_checksum = RawBlocks.checksum.get(block_number)\n",
    "    print('>>> Checksum Returned From GET Server ', block_checksum)\n",
    "    if block_checksum != None and current_checksum != block_checksum:\n",
    "      print('>>> Corrupt Block Detected: Checksum Mismatch')\n",
    "      has_error = True\n",
    "# ...\n",
    "# ...\n",
    "```\n",
    "\n",
    "It takes a long time for a block to corrupt, to simulate this, `cblk` parameter is provided with the block index while spinning the server which is used to corrupt the checksum of the block.\n",
    "\n",
    "### Recovery ###\n",
    "\n",
    "#### Block Recovery ####\n",
    "\n",
    "As per the previous discussion, the block recovery utilizes the other data blocks and the parity to recover from the corruption.\n",
    "\n",
    "The process involves the following steps.\n",
    "\n",
    "   1. determine the block_index of the corrupt block\n",
    "   2. Fetch the data strip and the parity server\n",
    "   3. Filter the corrupt block from strip\n",
    "   4. Fetch teh data blocks and parity block\n",
    "   5. Use parity function to recover the data\n",
    "\n",
    "#### Server Recovery ####\n",
    "\n",
    "Each server contains BLOCK_SIZE number of blocks and recovering data for all of the blocks involves recovering each of the blocks, including the parity blocks.\n",
    "\n",
    "Along with block recovery function, additional parity block recovery procedure is written which is slighly different fromt he data block recovery.\n",
    "\n",
    "![Figure 3. server #2 in failure state](image-4.png)\n",
    "\n",
    "The process for parity recovery involves the following steps -\n",
    "\n",
    "  1. determine the block index of the corrupt block\n",
    "  2. Fetch the data strip\n",
    "  3. use parity function to recover the data\n",
    "\n",
    "The rest of the server recovery involves recovering each of the data and parity block one at a time.\n",
    "\n",
    "```python\n",
    "# RecoverServer()\n",
    "# ..\n",
    "# ..\n",
    "  # virtual to physical will skip the parity servers while mapping virtual block numbers\n",
    "  parity_block_physical_ids = [fsconfig.MAX_SERVERS - int(server_id) - 1 + idx * 4 for idx in range(0, 64)]\n",
    "\n",
    "  data_block_physical_ids = [idx for idx in range(0, 192) if idx not in parity_block_physical_ids]\n",
    "  data_block_virtual_ids = [self.MapPhysicalAddressToVirtualBlock(int(server_id), idx) for idx in data_block_physical_ids]\n",
    "\n",
    "  # recover data blocks - RecoverDataBlock()\n",
    "  for block in zip(data_block_physical_ids, data_block_virtual_ids):\n",
    "     recovered_block_data = self.RecoverDataBlock((int(server_id), block[0]), block[1])\n",
    "     self.Put(block[1], recovered_block_data)\n",
    "\n",
    "  # recover parity blocks - RecoverParityBlock()\n",
    "  for block_idx in parity_block_physical_ids:\n",
    "     recovered_parity_data = self.RecoverParityBlock(block_idx)\n",
    "     self.SinglePut(int(server_id), block_idx, recovered_parity_data)\n",
    "# ..\n",
    "# ..\n",
    "```\n",
    "\n",
    "We use the SinglePut method for parity recover instead of the Put for data recovery, because the Put method utilizes the virtual to physical mapping - which skips the parity blocks.\n",
    "\n",
    "#### Failover ####\n",
    "\n",
    "While the server is in failure state, the client will try to read the data and it will log `Server_Disconnected` error but without failing the command.\n",
    "\n",
    "The read operations will continue to work by recovering the data utilizing other blocks on the strip.\n",
    "\n",
    "## Evaluation <a name=\"evaluation\"></a> ##\n",
    "\n",
    "Describe how you tested your program and, for EEL-5737 students, how you evaluated the load distribution.\n",
    "\n",
    "## Reproducibility <a name=\"reproducibility\"></a> ##\n",
    "\n",
    "Running the project:\n",
    "\n",
    "To run a server: `python3 ./blockserver.py -nb 256 -bs 128 -port <start_port>`\n",
    "\n",
    "The server ports numbers should differ by atmost by 1.\n",
    "\n",
    "After all of the servers are up and running. We connect a client -\n",
    "\n",
    "To run the client: `python3 ./fsmain.py -port 8000 -cid 0 -startport start_port -ns 4 -nb total_data_blocks`\n",
    "\n",
    "Total number of blocks = `-nb = (number_of_servers - 1) * (number_of_block_size_each_server)`\n",
    "\n",
    "### Failover and Server Failure ###\n",
    "\n",
    "1. Create a file through client\n",
    "2. Stop server #2\n",
    "3. Try to locate the file using `ls` \n",
    "4. `Server Disconnected` message should be printed\n",
    "5. However, client will not fail and file will still show up\n",
    "6. Restart the server #2\n",
    "7. run `repair 2` on client and wait until the command is executing\n",
    "8. No error message will be printed\n",
    "9. client will resume normal operations\n",
    "\n",
    "### Corrupt block ###\n",
    "\n",
    "1. For any one of the servers we add additional `-cblk block_number` argument.\n",
    "2. Connect the client\n",
    "3. command\n",
    "\n",
    "## Conclusions <a name=\"conclusions\"></a> ##\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
